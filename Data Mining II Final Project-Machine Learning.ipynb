{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from time import sleep\n",
    "import os\n",
    "import errno\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.utils import np_utils\n",
    "#from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sagarsahoo/Downloads\n"
     ]
    }
   ],
   "source": [
    "cd /Users/sagarsahoo/Downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_remove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError as e:  # this would be \"except OSError, e:\" before Python 2.6\n",
    "        if e.errno != errno.ENOENT:  # errno.ENOENT = no such file or directory\n",
    "            raise  # re-raise exception if a different error occurred\n",
    "\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        d = pickle.load(fo, encoding='bytes')\n",
    "    return d\n",
    "\n",
    "\n",
    "def read_data(folder):\n",
    "    x_data_temp = []\n",
    "    y_data_temp = []\n",
    "    x_test_data_temp = []\n",
    "    y_test_data_temp = []\n",
    "    # We don't use numpy's vstack here as that would be wasteful, because every time you do a vstack, numpy would end\n",
    "    # up copying the whole array to a new location. Hence we use a little trick to first store the data in a list and\n",
    "    # then convert it to an numpy array\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".meta\") or file.endswith(\".html\"):\n",
    "            print(\"Ignoring html and meta files\")\n",
    "        elif \"test_batch\" in file:\n",
    "            # test data file detected. we are gonna load it separately\n",
    "            test_data_temp = unpickle(folder + \"/\" + file)\n",
    "            x_test_data_temp.append(test_data_temp[b'data'])\n",
    "            y_test_data_temp.append(test_data_temp[b'labels'])\n",
    "        else:\n",
    "            temp_data = unpickle(folder + \"/\" + file)\n",
    "            x_data_temp.append(temp_data[b'data'])\n",
    "            y_data_temp.append(temp_data[b'labels'])\n",
    "    x_data = array(x_data_temp)\n",
    "    y_data = array(y_data_temp)\n",
    "    x_test_data = array(x_test_data_temp)\n",
    "    y_test_data = array(y_test_data_temp)\n",
    "    return [x_data, y_data, x_test_data, y_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring html and meta files\n",
      "Ignoring html and meta files\n"
     ]
    }
   ],
   "source": [
    "X_train_temp, y_train_temp, X_test_temp, y_test_temp = read_data(\"cifar-10-batches-py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10000, 3072) 3 <class 'numpy.ndarray'>\n",
      "(5, 10000) 2 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train_temp.shape, X_train_temp.ndim, type(X_train_temp))\n",
    "print(y_train_temp.shape, y_train_temp.ndim, type(y_train_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072) 2 <class 'numpy.ndarray'>\n",
      "(50000,) 1 <class 'numpy.ndarray'>\n",
      "(10000, 3072) 2 <class 'numpy.ndarray'>\n",
      "(10000,) 1 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_train_temp = X_train_temp.reshape(X_train_temp.shape[0] * X_train_temp.shape[1], X_train_temp.shape[2])\n",
    "y_train_temp = y_train_temp.reshape(y_train_temp.shape[0] * y_train_temp.shape[1])\n",
    "\n",
    "# Similarly for X_test_temp and y_test_data\n",
    "\n",
    "X_test_temp = X_test_temp.reshape(X_test_temp.shape[0] * X_test_temp.shape[1], X_test_temp.shape[2])\n",
    "y_test_temp = y_test_temp.reshape(y_test_temp.shape[0] * y_test_temp.shape[1])\n",
    "\n",
    "print(X_train_temp.shape, X_train_temp.ndim, type(X_train_temp))\n",
    "print(y_train_temp.shape, y_train_temp.ndim, type(y_train_temp))\n",
    "\n",
    "print(X_test_temp.shape, X_test_temp.ndim, type(X_test_temp))\n",
    "print(y_test_temp.shape, y_test_temp.ndim, type(y_test_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train_temp, y_train_temp, random_state=4)\n",
    "X_test, y_test = shuffle(X_test_temp, y_test_temp, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and y in training and val data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=13433382)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.65038275e+03, -1.95174099e+03,  3.17917466e+01, ...,\n",
       "         5.46725631e-01, -2.66012072e-01,  5.11939338e-01],\n",
       "       [-2.16472184e+02,  1.61471474e+03,  1.61462560e+03, ...,\n",
       "         1.39951359e-01,  4.25294685e-01,  6.76194147e-04],\n",
       "       [ 1.89235266e+03, -2.90273939e+03,  7.26465489e+02, ...,\n",
       "         2.26548715e-02,  1.07499696e-01, -5.30930803e-01],\n",
       "       ...,\n",
       "       [-1.88527631e+02,  7.40872823e+02,  3.70187083e+02, ...,\n",
       "         2.49327761e-01,  2.43933006e-01,  1.28979018e-01],\n",
       "       [-1.35009278e+03,  2.93335128e+02, -6.68738936e+02, ...,\n",
       "         1.22121856e-01, -2.67951781e-01, -8.70771836e-02],\n",
       "       [-1.88531819e+02,  7.94615150e+02,  3.13328845e+02, ...,\n",
       "        -1.53393912e-01,  5.40372176e-02,  7.22672867e-02]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  (3072,)\n",
      "k:   657\n",
      "(40000, 657)\n",
      "(40000,)\n",
      "(10000, 657)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Explained Variance: ', pca.explained_variance_.shape)\n",
    "\n",
    "k = 0\n",
    "total = sum(pca.explained_variance_)\n",
    "current_sum = 0\n",
    "\n",
    "while(current_sum / total < 0.99):\n",
    "    current_sum += pca.explained_variance_[k]\n",
    "    k += 1\n",
    "    \n",
    "print('k:  ',k)\n",
    "\n",
    "\n",
    "## Applying PCA with k calcuated above\n",
    "\n",
    "pca = PCA(n_components=k, whiten=True)\n",
    "\n",
    "x_train_pca = pca.fit_transform(X_train)\n",
    "x_val_pca = pca.transform(X_val)\n",
    "\n",
    "\n",
    "print(x_train_pca.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val_pca.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dtc = DecisionTreeClassifier(random_state=0,max_depth=60,min_samples_split=80)\n",
    "\n",
    "# fit the grid with data\n",
    "dtc_grid.fit(x_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dtc_val_pred = dtc_grid.best_estimator_.predict(x_val_pca)\n",
    "y_dtc_insample_pred = dtc_grid.best_estimator_.predict(x_train_pca)\n",
    "\n",
    "\n",
    "print('DecisionTreeClassifier Validation Accuracy : ',metrics.accuracy_score(y_dtc_val_pred,y_val))\n",
    "print('DecisionTreeClassifier In-Sample Accuracy : ',metrics.accuracy_score(y_dtc_insample_pred,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# fit the grid with data\n",
    "rfc.fit(x_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rfc_val_pred = rfc.predict(x_val_pca)\n",
    "y_rfc_insample_pred = rfc.predict(x_train_pca)\n",
    "\n",
    "\n",
    "print('RandomForestClassifier Validation Accuracy : ',metrics.accuracy_score(y_rfc_val_pred,y_val))\n",
    "print('RandomForestClassifier In-Sample Accuracy : ',metrics.accuracy_score(y_rfc_insample_pred,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(x_train_pca,y_train)\n",
    "\n",
    "y_val_gbc_pred=GBC.predict(x_val_pca)\n",
    "y_gbc_insample_pred=GBC.predict(x_val_pca)\n",
    "\n",
    "\n",
    "print('Gradient Boosting Validation Accuracy : ' ,accuracy_score(y_val, y_val_gbc_pred))\n",
    "print('Gradient Boosting Training Accuracy : ',accuracy_score(y_gbc_insample_pred,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM - RBF Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svclassifier = SVC(kernel='rbf',probability=True)\n",
    "rbf_svclassifier.fit(x_train_pca, y_train)\n",
    "\n",
    "y_val_rbf_pred = rbf_svclassifier.predict(x_val_pca)\n",
    "y_insample_rbf_pred = rbf_svclassifier.predict(x_train_pca)\n",
    "\n",
    "print( 'RBF SVM Validation Accuracy : ', accuracy_score(y_val, y_val_rbf_pred))\n",
    "print('RBF SVM In-Sample Accuracy : ', accuracy_score(y_train, y_insample_rbf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
